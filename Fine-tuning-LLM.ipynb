{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqM-T1RTzY6C"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth?tab=readme-ov-file#-installation-instructions).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
        "\n",
        "Features in the notebook:\n",
        "1. Uses Maxime Labonne's [FineTome 100K](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset.\n",
        "1. Convert ShareGPT to HuggingFace format via `standardize_sharegpt`\n",
        "2. Train on Completions / Assistant only via `train_on_responses_only`\n",
        "3. Unsloth now supports Torch 2.4, all TRL & Xformers versions & Python 3.12!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-DTuRyJHbTy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2v_X2fA0Df5"
      },
      "source": [
        "* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n",
        "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
        "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
        "* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n",
        "* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "66774fd9-e587-4ac3-fe63-65800c2b8079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-1B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = \"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\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_repo = \"jacopoda/lora_model\""
      ],
      "metadata": {
        "id": "R5GC8WVkgRep"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6bZsfBuZDeCL"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
        "```\n",
        "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
        "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
        "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
        "```\n",
        "to\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oPXzJZzHEgXe"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "a727bdde-db84-4e9e-a2b2-19fd99565b10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?',\n",
              "  'role': 'user'},\n",
              " {'content': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzTdMtvGE6w"
      },
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "7fc83c9e-9c1d-450c-a5a2-769e8e46181f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "'''\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    checkpoint_repo,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,  # Use FP16 if GPU is available\n",
        "    device_map=\"auto\",  # Automatically map model layers to available GPUs\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_repo)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "L7b0Ox_OhIM-",
        "outputId": "af32674c-7931-467a-a777-63a959a48487"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel = AutoModelForCausalLM.from_pretrained(\\n    checkpoint_repo,\\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,  # Use FP16 if GPU is available\\n    device_map=\"auto\",  # Automatically map model layers to available GPUs\\n)\\ntokenizer = AutoTokenizer.from_pretrained(checkpoint_repo)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jHQF6Gsq2hD",
        "outputId": "83c5da03-cf40-4641-dd6d-db18e3bba443"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save checkpoints\n",
        "drive_output_dir = \"/content/drive/MyDrive/training_checkpoints\""
      ],
      "metadata": {
        "id": "Xn-pBsFGq_C1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(drive_output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "pU1Czy_Ysxfm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        #max_steps = 7850,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = drive_output_dir,\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "        save_steps= 150,  # Save a checkpoint every 150 steps\n",
        "        save_total_limit=3,  # Keep only the last 3 checkpoints\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "juQiExuBG5Bt"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "LtsMVtlkUhja",
        "outputId": "7a3b3058-d695-4fe5-a2af-43dc893277d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "d88ca684-83d0-4482-e29c-e36f6282915e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                \\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "2177eae0-9c2c-46ce-a708-5273a99155f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "2.49 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_checkpoint_dir = \"/content/drive/MyDrive/training_checkpoints/checkpoint-10\""
      ],
      "metadata": {
        "id": "qjMwsxMRrYPy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints = [\n",
        "    os.path.join(drive_output_dir, d) for d in os.listdir(drive_output_dir) if d.startswith(\"checkpoint-\")\n",
        "]\n",
        "\n",
        "# Extract the step number from the checkpoint names\n",
        "if checkpoints:\n",
        "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
        "    print(f\"Resuming from the latest checkpoint: {latest_checkpoint}\")\n",
        "else:\n",
        "    latest_checkpoint = None\n",
        "    print(\"No checkpoints found. Starting training from scratch.\")\n",
        "\n",
        "# Use the latest checkpoint\n",
        "if latest_checkpoint:\n",
        "     trainer_stats = trainer.train(resume_from_checkpoint=latest_checkpoint)\n",
        "else:\n",
        "    trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cHLuO88lt4Z6",
        "outputId": "c9ba8b88-f9de-4145-d0ad-5b7b032ae23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from the latest checkpoint: /content/drive/MyDrive/training_checkpoints/checkpoint-10420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3354: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 100,000 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 12,500\n",
            " \"-____-\"     Number of trainable parameters = 11,272,192\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3033: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_rng_state = torch.load(rng_file)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11128' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11128/12500 40:13 < 1:18:09, 0.29 it/s, Epoch 0.89/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10421</td>\n",
              "      <td>0.650500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10422</td>\n",
              "      <td>0.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10423</td>\n",
              "      <td>0.880900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10424</td>\n",
              "      <td>1.032600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10425</td>\n",
              "      <td>0.467300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10426</td>\n",
              "      <td>0.752800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10427</td>\n",
              "      <td>0.915200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10428</td>\n",
              "      <td>1.174600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10429</td>\n",
              "      <td>0.628200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10430</td>\n",
              "      <td>0.882800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10431</td>\n",
              "      <td>0.635600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10432</td>\n",
              "      <td>0.790700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10433</td>\n",
              "      <td>1.163900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10434</td>\n",
              "      <td>0.866500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10435</td>\n",
              "      <td>0.962600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10436</td>\n",
              "      <td>1.119400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10437</td>\n",
              "      <td>0.884700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10438</td>\n",
              "      <td>0.634800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10439</td>\n",
              "      <td>0.867100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10440</td>\n",
              "      <td>0.594400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10441</td>\n",
              "      <td>0.942400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10442</td>\n",
              "      <td>0.715200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10443</td>\n",
              "      <td>0.792100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10444</td>\n",
              "      <td>0.790600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10445</td>\n",
              "      <td>0.811200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10446</td>\n",
              "      <td>0.662900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10447</td>\n",
              "      <td>0.609500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10448</td>\n",
              "      <td>0.908900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10449</td>\n",
              "      <td>0.946400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10450</td>\n",
              "      <td>0.843600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10451</td>\n",
              "      <td>0.566800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10452</td>\n",
              "      <td>0.600300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10453</td>\n",
              "      <td>0.768900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10454</td>\n",
              "      <td>0.774500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10455</td>\n",
              "      <td>0.930200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10456</td>\n",
              "      <td>1.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10457</td>\n",
              "      <td>0.592100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10458</td>\n",
              "      <td>1.028900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10459</td>\n",
              "      <td>0.816900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10460</td>\n",
              "      <td>0.628900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10461</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10462</td>\n",
              "      <td>0.705600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10463</td>\n",
              "      <td>0.634300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10464</td>\n",
              "      <td>0.900200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10465</td>\n",
              "      <td>0.662800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10466</td>\n",
              "      <td>0.761700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10467</td>\n",
              "      <td>0.624500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10468</td>\n",
              "      <td>0.925700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10469</td>\n",
              "      <td>0.843200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10470</td>\n",
              "      <td>0.912000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10471</td>\n",
              "      <td>0.699200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10472</td>\n",
              "      <td>0.756000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10473</td>\n",
              "      <td>0.665000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10474</td>\n",
              "      <td>1.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10475</td>\n",
              "      <td>0.747400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10476</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10477</td>\n",
              "      <td>0.639900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10478</td>\n",
              "      <td>0.511600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10479</td>\n",
              "      <td>0.933600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10480</td>\n",
              "      <td>0.766000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10481</td>\n",
              "      <td>0.554400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10482</td>\n",
              "      <td>0.458800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10483</td>\n",
              "      <td>0.815800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10484</td>\n",
              "      <td>0.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10485</td>\n",
              "      <td>1.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10486</td>\n",
              "      <td>0.767000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10487</td>\n",
              "      <td>0.643800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10488</td>\n",
              "      <td>0.646200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10489</td>\n",
              "      <td>0.752500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10490</td>\n",
              "      <td>0.708700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10491</td>\n",
              "      <td>0.951200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10492</td>\n",
              "      <td>0.671000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10493</td>\n",
              "      <td>0.865400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10494</td>\n",
              "      <td>0.913300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10495</td>\n",
              "      <td>0.882100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10496</td>\n",
              "      <td>0.831100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10497</td>\n",
              "      <td>0.517700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10498</td>\n",
              "      <td>0.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10499</td>\n",
              "      <td>0.675600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10501</td>\n",
              "      <td>1.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10502</td>\n",
              "      <td>0.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10503</td>\n",
              "      <td>1.150400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10504</td>\n",
              "      <td>0.726300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10505</td>\n",
              "      <td>0.825200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10506</td>\n",
              "      <td>0.700300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10507</td>\n",
              "      <td>0.872400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10508</td>\n",
              "      <td>0.883400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10509</td>\n",
              "      <td>0.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10510</td>\n",
              "      <td>0.759400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10511</td>\n",
              "      <td>1.241000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10512</td>\n",
              "      <td>0.693400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10513</td>\n",
              "      <td>0.708600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10514</td>\n",
              "      <td>0.739500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10515</td>\n",
              "      <td>0.618600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10516</td>\n",
              "      <td>0.800200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10517</td>\n",
              "      <td>0.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10518</td>\n",
              "      <td>0.874000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10519</td>\n",
              "      <td>1.152700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10520</td>\n",
              "      <td>0.616400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10521</td>\n",
              "      <td>0.511600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10522</td>\n",
              "      <td>0.545600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10523</td>\n",
              "      <td>0.892000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10524</td>\n",
              "      <td>1.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10525</td>\n",
              "      <td>0.732200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10526</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10527</td>\n",
              "      <td>0.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10528</td>\n",
              "      <td>0.969200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10529</td>\n",
              "      <td>0.903200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10530</td>\n",
              "      <td>0.846300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10531</td>\n",
              "      <td>0.901700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10532</td>\n",
              "      <td>0.595200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10533</td>\n",
              "      <td>0.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10534</td>\n",
              "      <td>1.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10535</td>\n",
              "      <td>0.586100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10536</td>\n",
              "      <td>0.882500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10537</td>\n",
              "      <td>0.789600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10538</td>\n",
              "      <td>0.761900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10539</td>\n",
              "      <td>0.594600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10540</td>\n",
              "      <td>0.976400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10541</td>\n",
              "      <td>0.805500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10542</td>\n",
              "      <td>1.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10543</td>\n",
              "      <td>0.875200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10544</td>\n",
              "      <td>0.759200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10545</td>\n",
              "      <td>0.653700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10546</td>\n",
              "      <td>0.783200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10547</td>\n",
              "      <td>0.755400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10548</td>\n",
              "      <td>0.561100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10549</td>\n",
              "      <td>0.642900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10550</td>\n",
              "      <td>0.576300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10551</td>\n",
              "      <td>0.783200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10552</td>\n",
              "      <td>0.710300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10553</td>\n",
              "      <td>0.967300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10554</td>\n",
              "      <td>0.815700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10555</td>\n",
              "      <td>0.809500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10556</td>\n",
              "      <td>0.783600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10557</td>\n",
              "      <td>0.947900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10558</td>\n",
              "      <td>0.665900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10559</td>\n",
              "      <td>0.980900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10560</td>\n",
              "      <td>0.832000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10561</td>\n",
              "      <td>0.706300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10562</td>\n",
              "      <td>0.913300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10563</td>\n",
              "      <td>0.883700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10564</td>\n",
              "      <td>0.801300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10565</td>\n",
              "      <td>1.190300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10566</td>\n",
              "      <td>0.424600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10567</td>\n",
              "      <td>0.797900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10568</td>\n",
              "      <td>0.694800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10569</td>\n",
              "      <td>0.764100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10570</td>\n",
              "      <td>1.056700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10571</td>\n",
              "      <td>0.476700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10572</td>\n",
              "      <td>0.760500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10573</td>\n",
              "      <td>0.518600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10574</td>\n",
              "      <td>1.039400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10575</td>\n",
              "      <td>0.759600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10576</td>\n",
              "      <td>0.580500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10577</td>\n",
              "      <td>0.980200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10578</td>\n",
              "      <td>0.721000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10579</td>\n",
              "      <td>0.902500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10580</td>\n",
              "      <td>1.054600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10581</td>\n",
              "      <td>1.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10582</td>\n",
              "      <td>0.929100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10583</td>\n",
              "      <td>0.909200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10584</td>\n",
              "      <td>0.720100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10585</td>\n",
              "      <td>0.527100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10586</td>\n",
              "      <td>1.036500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10587</td>\n",
              "      <td>0.784200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10588</td>\n",
              "      <td>0.676500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10589</td>\n",
              "      <td>0.899200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10590</td>\n",
              "      <td>0.682400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10591</td>\n",
              "      <td>0.892700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10592</td>\n",
              "      <td>0.751900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10593</td>\n",
              "      <td>0.885600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10594</td>\n",
              "      <td>0.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10595</td>\n",
              "      <td>0.715300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10596</td>\n",
              "      <td>0.546500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10597</td>\n",
              "      <td>0.864100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10598</td>\n",
              "      <td>0.876900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10599</td>\n",
              "      <td>1.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.908400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10601</td>\n",
              "      <td>0.610500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10602</td>\n",
              "      <td>0.780800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10603</td>\n",
              "      <td>0.788700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10604</td>\n",
              "      <td>0.703500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10605</td>\n",
              "      <td>0.940900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10606</td>\n",
              "      <td>0.815600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10607</td>\n",
              "      <td>0.782700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10608</td>\n",
              "      <td>0.753500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10609</td>\n",
              "      <td>0.837200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10610</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10611</td>\n",
              "      <td>1.212400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10612</td>\n",
              "      <td>0.839500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10613</td>\n",
              "      <td>0.775100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10614</td>\n",
              "      <td>0.928400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10615</td>\n",
              "      <td>1.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10616</td>\n",
              "      <td>0.752400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10617</td>\n",
              "      <td>0.621400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10618</td>\n",
              "      <td>0.803300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10619</td>\n",
              "      <td>0.827400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10620</td>\n",
              "      <td>0.599500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10621</td>\n",
              "      <td>0.582900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10622</td>\n",
              "      <td>0.647100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10623</td>\n",
              "      <td>0.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10624</td>\n",
              "      <td>0.809800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10625</td>\n",
              "      <td>0.859900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10626</td>\n",
              "      <td>0.598300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10627</td>\n",
              "      <td>0.805600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10628</td>\n",
              "      <td>0.896600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10629</td>\n",
              "      <td>0.507800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10630</td>\n",
              "      <td>0.588200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10631</td>\n",
              "      <td>0.967800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10632</td>\n",
              "      <td>0.741000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10633</td>\n",
              "      <td>0.879600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10634</td>\n",
              "      <td>1.020800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10635</td>\n",
              "      <td>0.826000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10636</td>\n",
              "      <td>0.672200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10637</td>\n",
              "      <td>0.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10638</td>\n",
              "      <td>0.892600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10639</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10640</td>\n",
              "      <td>0.836700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10641</td>\n",
              "      <td>0.668700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10642</td>\n",
              "      <td>0.934200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10643</td>\n",
              "      <td>0.959200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10644</td>\n",
              "      <td>0.779700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10645</td>\n",
              "      <td>0.844900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10646</td>\n",
              "      <td>1.166100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10647</td>\n",
              "      <td>0.579100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10648</td>\n",
              "      <td>0.933800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10649</td>\n",
              "      <td>0.974200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10650</td>\n",
              "      <td>0.817300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10651</td>\n",
              "      <td>1.055000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10652</td>\n",
              "      <td>1.221400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10653</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10654</td>\n",
              "      <td>0.906400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10655</td>\n",
              "      <td>0.630100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10656</td>\n",
              "      <td>0.761400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10657</td>\n",
              "      <td>1.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10658</td>\n",
              "      <td>1.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10659</td>\n",
              "      <td>0.649800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10660</td>\n",
              "      <td>0.764100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10661</td>\n",
              "      <td>0.843100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10662</td>\n",
              "      <td>0.586500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10663</td>\n",
              "      <td>0.676200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10664</td>\n",
              "      <td>0.627500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10665</td>\n",
              "      <td>1.131700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10666</td>\n",
              "      <td>0.824100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10667</td>\n",
              "      <td>0.968600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10668</td>\n",
              "      <td>0.919600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10669</td>\n",
              "      <td>0.728300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10670</td>\n",
              "      <td>0.878900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10671</td>\n",
              "      <td>0.682300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10672</td>\n",
              "      <td>0.832100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10673</td>\n",
              "      <td>0.634700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10674</td>\n",
              "      <td>0.955600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10675</td>\n",
              "      <td>0.647400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10676</td>\n",
              "      <td>0.646300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10677</td>\n",
              "      <td>0.583300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10678</td>\n",
              "      <td>0.883300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10679</td>\n",
              "      <td>0.716400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10680</td>\n",
              "      <td>1.088700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10681</td>\n",
              "      <td>0.810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10682</td>\n",
              "      <td>0.740900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10683</td>\n",
              "      <td>0.898300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10684</td>\n",
              "      <td>0.687300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10685</td>\n",
              "      <td>0.880900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10686</td>\n",
              "      <td>0.815900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10687</td>\n",
              "      <td>0.643500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10688</td>\n",
              "      <td>0.880700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10689</td>\n",
              "      <td>0.927500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10690</td>\n",
              "      <td>0.598600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10691</td>\n",
              "      <td>0.944900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10692</td>\n",
              "      <td>0.593200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10693</td>\n",
              "      <td>0.460600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10694</td>\n",
              "      <td>0.648100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10695</td>\n",
              "      <td>0.777800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10696</td>\n",
              "      <td>0.615900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10697</td>\n",
              "      <td>0.918000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10698</td>\n",
              "      <td>0.881000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10699</td>\n",
              "      <td>1.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.795900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10701</td>\n",
              "      <td>0.763500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10702</td>\n",
              "      <td>0.734200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10703</td>\n",
              "      <td>0.830900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10704</td>\n",
              "      <td>1.024400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10705</td>\n",
              "      <td>0.723600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10706</td>\n",
              "      <td>0.911300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10707</td>\n",
              "      <td>0.435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10708</td>\n",
              "      <td>0.592400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10709</td>\n",
              "      <td>0.816000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10710</td>\n",
              "      <td>0.939100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10711</td>\n",
              "      <td>0.606100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10712</td>\n",
              "      <td>0.869700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10713</td>\n",
              "      <td>0.594900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10714</td>\n",
              "      <td>0.833900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10715</td>\n",
              "      <td>0.769000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10716</td>\n",
              "      <td>0.943800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10717</td>\n",
              "      <td>0.701700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10718</td>\n",
              "      <td>0.944100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10719</td>\n",
              "      <td>0.364600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10720</td>\n",
              "      <td>0.484100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10721</td>\n",
              "      <td>0.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10722</td>\n",
              "      <td>0.793300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10723</td>\n",
              "      <td>0.836900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10724</td>\n",
              "      <td>1.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10725</td>\n",
              "      <td>0.592700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10726</td>\n",
              "      <td>0.588200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10727</td>\n",
              "      <td>0.857300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10728</td>\n",
              "      <td>0.669800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10729</td>\n",
              "      <td>0.874500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10730</td>\n",
              "      <td>0.624200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10731</td>\n",
              "      <td>0.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10732</td>\n",
              "      <td>0.580900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10733</td>\n",
              "      <td>0.836000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10734</td>\n",
              "      <td>0.615200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10735</td>\n",
              "      <td>0.772600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10736</td>\n",
              "      <td>0.663500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10737</td>\n",
              "      <td>0.913700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10738</td>\n",
              "      <td>0.967800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10739</td>\n",
              "      <td>0.827200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10740</td>\n",
              "      <td>0.712000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10741</td>\n",
              "      <td>0.826000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10742</td>\n",
              "      <td>0.565300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10743</td>\n",
              "      <td>0.498200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10744</td>\n",
              "      <td>0.971900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10745</td>\n",
              "      <td>0.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10746</td>\n",
              "      <td>0.731200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10747</td>\n",
              "      <td>0.945000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10748</td>\n",
              "      <td>0.563700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10749</td>\n",
              "      <td>0.592800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10750</td>\n",
              "      <td>0.793100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10751</td>\n",
              "      <td>0.989200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10752</td>\n",
              "      <td>1.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10753</td>\n",
              "      <td>1.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10754</td>\n",
              "      <td>0.695500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10755</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10756</td>\n",
              "      <td>0.580400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10757</td>\n",
              "      <td>0.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10758</td>\n",
              "      <td>0.578400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10759</td>\n",
              "      <td>0.826100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10760</td>\n",
              "      <td>0.628000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10761</td>\n",
              "      <td>0.793900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10762</td>\n",
              "      <td>1.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10763</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10764</td>\n",
              "      <td>0.818300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10765</td>\n",
              "      <td>1.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10766</td>\n",
              "      <td>0.381800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10767</td>\n",
              "      <td>0.797100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10768</td>\n",
              "      <td>0.936800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10769</td>\n",
              "      <td>1.167500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10770</td>\n",
              "      <td>0.771000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10771</td>\n",
              "      <td>0.765500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10772</td>\n",
              "      <td>0.677300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10773</td>\n",
              "      <td>0.662300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10774</td>\n",
              "      <td>1.123100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10775</td>\n",
              "      <td>0.877800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10776</td>\n",
              "      <td>0.897900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10777</td>\n",
              "      <td>0.654100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10778</td>\n",
              "      <td>0.445700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10779</td>\n",
              "      <td>0.799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10780</td>\n",
              "      <td>0.842000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10781</td>\n",
              "      <td>0.778400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10782</td>\n",
              "      <td>0.753700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10783</td>\n",
              "      <td>0.503100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10784</td>\n",
              "      <td>0.774400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10785</td>\n",
              "      <td>1.045900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10786</td>\n",
              "      <td>0.818100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10787</td>\n",
              "      <td>0.819200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10788</td>\n",
              "      <td>1.319300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10789</td>\n",
              "      <td>0.794300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10790</td>\n",
              "      <td>0.725600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10791</td>\n",
              "      <td>0.950800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10792</td>\n",
              "      <td>0.848600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10793</td>\n",
              "      <td>0.680700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10794</td>\n",
              "      <td>0.652500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10795</td>\n",
              "      <td>0.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10796</td>\n",
              "      <td>1.105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10797</td>\n",
              "      <td>0.632200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10798</td>\n",
              "      <td>0.551400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10799</td>\n",
              "      <td>0.885300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>1.116200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10801</td>\n",
              "      <td>0.926900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10802</td>\n",
              "      <td>0.838000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10803</td>\n",
              "      <td>1.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10804</td>\n",
              "      <td>1.189600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10805</td>\n",
              "      <td>0.835700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10806</td>\n",
              "      <td>0.719900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10807</td>\n",
              "      <td>0.619400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10808</td>\n",
              "      <td>0.769000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10809</td>\n",
              "      <td>0.654000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10810</td>\n",
              "      <td>0.741600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10811</td>\n",
              "      <td>0.635300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10812</td>\n",
              "      <td>0.866200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10813</td>\n",
              "      <td>0.986200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10814</td>\n",
              "      <td>0.720700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10815</td>\n",
              "      <td>0.580100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10816</td>\n",
              "      <td>0.528000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10817</td>\n",
              "      <td>0.787300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10818</td>\n",
              "      <td>0.683000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10819</td>\n",
              "      <td>0.711500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10820</td>\n",
              "      <td>0.927100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10821</td>\n",
              "      <td>0.884600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10822</td>\n",
              "      <td>0.850400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10823</td>\n",
              "      <td>0.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10824</td>\n",
              "      <td>0.728400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10825</td>\n",
              "      <td>0.719400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10826</td>\n",
              "      <td>0.608600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10827</td>\n",
              "      <td>0.661600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10828</td>\n",
              "      <td>0.735600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10829</td>\n",
              "      <td>0.873700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10830</td>\n",
              "      <td>0.812600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10831</td>\n",
              "      <td>0.828000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10832</td>\n",
              "      <td>0.798400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10833</td>\n",
              "      <td>0.587700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10834</td>\n",
              "      <td>0.679200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10835</td>\n",
              "      <td>0.772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10836</td>\n",
              "      <td>0.925100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10837</td>\n",
              "      <td>0.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10838</td>\n",
              "      <td>0.894600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10839</td>\n",
              "      <td>0.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10840</td>\n",
              "      <td>0.874200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10841</td>\n",
              "      <td>0.996200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10842</td>\n",
              "      <td>0.570600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10843</td>\n",
              "      <td>0.813100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10844</td>\n",
              "      <td>0.687800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10845</td>\n",
              "      <td>0.633200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10846</td>\n",
              "      <td>1.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10847</td>\n",
              "      <td>0.828100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10848</td>\n",
              "      <td>0.874400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10849</td>\n",
              "      <td>0.593300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10850</td>\n",
              "      <td>0.971900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10851</td>\n",
              "      <td>1.136400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10852</td>\n",
              "      <td>0.708900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10853</td>\n",
              "      <td>1.138400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10854</td>\n",
              "      <td>0.793500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10855</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10856</td>\n",
              "      <td>0.737500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10857</td>\n",
              "      <td>1.189800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10858</td>\n",
              "      <td>0.832700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10859</td>\n",
              "      <td>0.607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10860</td>\n",
              "      <td>0.540500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10861</td>\n",
              "      <td>0.733100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10862</td>\n",
              "      <td>1.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10863</td>\n",
              "      <td>0.865500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10864</td>\n",
              "      <td>0.782500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10865</td>\n",
              "      <td>0.733300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10866</td>\n",
              "      <td>0.727000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10867</td>\n",
              "      <td>0.869900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10868</td>\n",
              "      <td>0.997800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10869</td>\n",
              "      <td>0.995800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10870</td>\n",
              "      <td>0.583300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10871</td>\n",
              "      <td>0.877400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10872</td>\n",
              "      <td>0.911400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10873</td>\n",
              "      <td>0.454500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10874</td>\n",
              "      <td>0.877300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10875</td>\n",
              "      <td>0.440600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10876</td>\n",
              "      <td>0.751600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10877</td>\n",
              "      <td>0.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10878</td>\n",
              "      <td>1.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10879</td>\n",
              "      <td>0.753500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10880</td>\n",
              "      <td>0.879100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10881</td>\n",
              "      <td>0.954900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10882</td>\n",
              "      <td>0.787800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10883</td>\n",
              "      <td>0.579200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10884</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10885</td>\n",
              "      <td>0.933100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10886</td>\n",
              "      <td>0.578400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10887</td>\n",
              "      <td>0.742100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10888</td>\n",
              "      <td>0.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10889</td>\n",
              "      <td>0.605600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10890</td>\n",
              "      <td>0.823400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10891</td>\n",
              "      <td>0.914100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10892</td>\n",
              "      <td>0.686400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10893</td>\n",
              "      <td>0.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10894</td>\n",
              "      <td>0.598900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10895</td>\n",
              "      <td>0.895700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10896</td>\n",
              "      <td>0.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10897</td>\n",
              "      <td>0.760800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10898</td>\n",
              "      <td>0.700600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10899</td>\n",
              "      <td>1.083500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.848200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10901</td>\n",
              "      <td>1.154500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10902</td>\n",
              "      <td>0.330300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10903</td>\n",
              "      <td>0.684200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10904</td>\n",
              "      <td>0.760300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10905</td>\n",
              "      <td>0.541800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10906</td>\n",
              "      <td>0.468800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10907</td>\n",
              "      <td>0.813700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10908</td>\n",
              "      <td>0.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10909</td>\n",
              "      <td>1.037100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10910</td>\n",
              "      <td>0.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10911</td>\n",
              "      <td>0.742600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10912</td>\n",
              "      <td>0.560700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10913</td>\n",
              "      <td>0.608500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10914</td>\n",
              "      <td>1.128200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10915</td>\n",
              "      <td>0.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10916</td>\n",
              "      <td>0.462000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10917</td>\n",
              "      <td>0.893400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10918</td>\n",
              "      <td>1.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10919</td>\n",
              "      <td>0.893500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10920</td>\n",
              "      <td>0.682300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10921</td>\n",
              "      <td>0.841700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10922</td>\n",
              "      <td>0.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10923</td>\n",
              "      <td>0.703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10924</td>\n",
              "      <td>0.670300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10925</td>\n",
              "      <td>0.939800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10926</td>\n",
              "      <td>1.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10927</td>\n",
              "      <td>0.984200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10928</td>\n",
              "      <td>0.761700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10929</td>\n",
              "      <td>0.554200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10930</td>\n",
              "      <td>0.797900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10931</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10932</td>\n",
              "      <td>0.860100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10933</td>\n",
              "      <td>0.672500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10934</td>\n",
              "      <td>0.432400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10935</td>\n",
              "      <td>0.639300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10936</td>\n",
              "      <td>1.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10937</td>\n",
              "      <td>0.993700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10938</td>\n",
              "      <td>0.784700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10939</td>\n",
              "      <td>0.808600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10940</td>\n",
              "      <td>0.474000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10941</td>\n",
              "      <td>0.732500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10942</td>\n",
              "      <td>1.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10943</td>\n",
              "      <td>0.588500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10944</td>\n",
              "      <td>0.617200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10945</td>\n",
              "      <td>0.619100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10946</td>\n",
              "      <td>0.940100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10947</td>\n",
              "      <td>0.910600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10948</td>\n",
              "      <td>0.999500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10949</td>\n",
              "      <td>0.715800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10950</td>\n",
              "      <td>1.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10951</td>\n",
              "      <td>0.755500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10952</td>\n",
              "      <td>0.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10953</td>\n",
              "      <td>0.667900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10954</td>\n",
              "      <td>1.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10955</td>\n",
              "      <td>0.706500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10956</td>\n",
              "      <td>0.942000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10957</td>\n",
              "      <td>0.954900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10958</td>\n",
              "      <td>0.657800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10959</td>\n",
              "      <td>0.834500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10960</td>\n",
              "      <td>0.890400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10961</td>\n",
              "      <td>1.038200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10962</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10963</td>\n",
              "      <td>0.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10964</td>\n",
              "      <td>0.885600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10965</td>\n",
              "      <td>0.726800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10966</td>\n",
              "      <td>0.916700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10967</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10968</td>\n",
              "      <td>1.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10969</td>\n",
              "      <td>1.064700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10970</td>\n",
              "      <td>0.930500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10971</td>\n",
              "      <td>0.894300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10972</td>\n",
              "      <td>0.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10973</td>\n",
              "      <td>0.950400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10974</td>\n",
              "      <td>0.745500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10975</td>\n",
              "      <td>0.761700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10976</td>\n",
              "      <td>1.208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10977</td>\n",
              "      <td>0.838200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10978</td>\n",
              "      <td>0.884000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10979</td>\n",
              "      <td>0.791000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10980</td>\n",
              "      <td>0.939900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10981</td>\n",
              "      <td>0.864500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10982</td>\n",
              "      <td>0.744200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10983</td>\n",
              "      <td>1.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10984</td>\n",
              "      <td>1.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10985</td>\n",
              "      <td>0.775200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10986</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10987</td>\n",
              "      <td>0.661400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10988</td>\n",
              "      <td>0.814800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10989</td>\n",
              "      <td>0.799500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10990</td>\n",
              "      <td>0.759800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10991</td>\n",
              "      <td>0.796600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10992</td>\n",
              "      <td>1.067500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10993</td>\n",
              "      <td>0.566800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10994</td>\n",
              "      <td>0.745100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10995</td>\n",
              "      <td>0.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10996</td>\n",
              "      <td>1.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10997</td>\n",
              "      <td>1.303300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10998</td>\n",
              "      <td>0.955100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10999</td>\n",
              "      <td>0.788500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.900600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11001</td>\n",
              "      <td>0.597000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11002</td>\n",
              "      <td>0.624000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11003</td>\n",
              "      <td>0.953000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11004</td>\n",
              "      <td>0.899900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11005</td>\n",
              "      <td>1.038900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11006</td>\n",
              "      <td>0.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11007</td>\n",
              "      <td>0.842600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11008</td>\n",
              "      <td>1.042600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11009</td>\n",
              "      <td>0.897000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11010</td>\n",
              "      <td>0.657400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11011</td>\n",
              "      <td>1.043200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11012</td>\n",
              "      <td>0.830700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11013</td>\n",
              "      <td>0.932000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11014</td>\n",
              "      <td>0.882800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11015</td>\n",
              "      <td>0.538900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11016</td>\n",
              "      <td>0.944900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11017</td>\n",
              "      <td>0.814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11018</td>\n",
              "      <td>1.053500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11019</td>\n",
              "      <td>0.778700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11020</td>\n",
              "      <td>0.872000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11021</td>\n",
              "      <td>1.053500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11022</td>\n",
              "      <td>0.568200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11023</td>\n",
              "      <td>0.743700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11024</td>\n",
              "      <td>0.784800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11025</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11026</td>\n",
              "      <td>1.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11027</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11028</td>\n",
              "      <td>0.719200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11029</td>\n",
              "      <td>0.887600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11030</td>\n",
              "      <td>1.083400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11031</td>\n",
              "      <td>0.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11032</td>\n",
              "      <td>0.727500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11033</td>\n",
              "      <td>0.817300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11034</td>\n",
              "      <td>0.836200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11035</td>\n",
              "      <td>0.543400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11036</td>\n",
              "      <td>0.863100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11037</td>\n",
              "      <td>0.668200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11038</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11039</td>\n",
              "      <td>0.654700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11040</td>\n",
              "      <td>0.622300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11041</td>\n",
              "      <td>0.766300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11042</td>\n",
              "      <td>0.630700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11043</td>\n",
              "      <td>0.612600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11044</td>\n",
              "      <td>1.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11045</td>\n",
              "      <td>0.841700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11046</td>\n",
              "      <td>1.032600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11047</td>\n",
              "      <td>0.825300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11048</td>\n",
              "      <td>0.870800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11049</td>\n",
              "      <td>1.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11050</td>\n",
              "      <td>0.791200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11051</td>\n",
              "      <td>0.805100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11052</td>\n",
              "      <td>0.862800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11053</td>\n",
              "      <td>0.880200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11054</td>\n",
              "      <td>0.725900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11055</td>\n",
              "      <td>1.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11056</td>\n",
              "      <td>1.160700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11057</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11058</td>\n",
              "      <td>1.068500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11059</td>\n",
              "      <td>0.799700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11060</td>\n",
              "      <td>0.673200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11061</td>\n",
              "      <td>0.581900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11062</td>\n",
              "      <td>0.790900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11063</td>\n",
              "      <td>0.947000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11064</td>\n",
              "      <td>0.809300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11065</td>\n",
              "      <td>1.024400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11066</td>\n",
              "      <td>0.921600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11067</td>\n",
              "      <td>0.720200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11068</td>\n",
              "      <td>0.848900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11069</td>\n",
              "      <td>1.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11070</td>\n",
              "      <td>0.546000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11071</td>\n",
              "      <td>0.512300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11072</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11073</td>\n",
              "      <td>0.792800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11074</td>\n",
              "      <td>0.876100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11075</td>\n",
              "      <td>0.860300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11076</td>\n",
              "      <td>0.851600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11077</td>\n",
              "      <td>0.730700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11078</td>\n",
              "      <td>0.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11079</td>\n",
              "      <td>0.854700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11080</td>\n",
              "      <td>0.794500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11081</td>\n",
              "      <td>0.804000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11082</td>\n",
              "      <td>0.732700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11083</td>\n",
              "      <td>0.947000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11084</td>\n",
              "      <td>0.720800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11085</td>\n",
              "      <td>0.703500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11086</td>\n",
              "      <td>0.831600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11087</td>\n",
              "      <td>0.635300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11088</td>\n",
              "      <td>0.385400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11089</td>\n",
              "      <td>0.737000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11090</td>\n",
              "      <td>0.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11091</td>\n",
              "      <td>0.642700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11092</td>\n",
              "      <td>0.688000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11093</td>\n",
              "      <td>0.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11094</td>\n",
              "      <td>0.914400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11095</td>\n",
              "      <td>0.744900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11096</td>\n",
              "      <td>0.639700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11097</td>\n",
              "      <td>0.923800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11098</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11099</td>\n",
              "      <td>0.645600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.725500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11101</td>\n",
              "      <td>0.721900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11102</td>\n",
              "      <td>0.517100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11103</td>\n",
              "      <td>0.762900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11104</td>\n",
              "      <td>0.495100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11105</td>\n",
              "      <td>1.026700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11106</td>\n",
              "      <td>0.511200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11107</td>\n",
              "      <td>0.710900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11108</td>\n",
              "      <td>0.507500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11109</td>\n",
              "      <td>0.758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11110</td>\n",
              "      <td>0.524200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11111</td>\n",
              "      <td>0.568300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11112</td>\n",
              "      <td>0.478300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11113</td>\n",
              "      <td>1.054300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11114</td>\n",
              "      <td>1.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11115</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11116</td>\n",
              "      <td>0.665500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11117</td>\n",
              "      <td>0.820200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11118</td>\n",
              "      <td>0.876500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11119</td>\n",
              "      <td>0.905500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11120</td>\n",
              "      <td>0.584500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11121</td>\n",
              "      <td>0.849000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11122</td>\n",
              "      <td>0.999700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11123</td>\n",
              "      <td>0.804600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11124</td>\n",
              "      <td>0.713200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11125</td>\n",
              "      <td>1.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11126</td>\n",
              "      <td>0.917500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL"
      },
      "outputs": [],
      "source": [
        "#trainer_stats = trainer.train(resume_from_checkpoint=latest_checkpoint)#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9"
      },
      "outputs": [],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR3gIAX-SM2q"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2pEuRb1r2Vg"
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upcOlWe7A1vc"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "model.push_to_hub(\"jacopoda/lora_model\", token = \"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\") # Online saving\n",
        "tokenizer.push_to_hub(\"jacopoda/lora_model\", token = \"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\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKX_XKs_BNZR"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"jacopoda/model\", tokenizer, save_method = \"merged_16bit\", token = \"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\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"jacopoda/model\", tokenizer, save_method = \"merged_4bit\", token = \"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\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"jacopoda/model\", tokenizer, save_method = \"lora\", token = \"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"jacopoda/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"jacopoda/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"jacopoda/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"jacopoda/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDp0zNpwe6U_"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt9CHJqO6p30"
      },
      "source": [
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n",
        "2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n",
        "3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n",
        "4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n",
        "5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n",
        "6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with 🤗 HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n",
        "7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n",
        "8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n",
        "9. [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)\n",
        "10. [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n",
        "11. [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n",
        "12. [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}